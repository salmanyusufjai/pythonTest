from google.cloud import bigquery
from google.auth import load_credentials_from_file
from datetime import datetime

# Load credentials from the user authentication JSON file
credentials, project_id = load_credentials_from_file("/path/to/your/user_authentication.json")

# Initialize BigQuery client with user credentials
client = bigquery.Client(credentials=credentials, project=project_id)

# Function to convert dd/mm/yyyy format to timestamp
def convert_to_timestamp(date_string):
    return datetime.strptime(date_string, '%d/%m/%Y').strftime('%Y-%m-%d')

# Function to fetch data using parameterized queries with dynamic project and dataset
def fetch_data_from_table(project, dataset, table_name, main_table, join_key, columns):
    try:
        params = [
            bigquery.ScalarQueryParameter("company_numbers", "STRING", main_table['company_number'].tolist()),
            bigquery.ScalarQueryParameter("processing_date", "TIMESTAMP", main_table['processingdate'].max()),
        ]
        column_str = ', '.join(columns)
        query = f"""
        SELECT company_number, {column_str}
        FROM `{project}.{dataset}.{table_name}`
        WHERE company_number IN UNNEST(@company_numbers)
        AND _partitiontime <= TIMESTAMP(@processing_date)
        ORDER BY _partitiontime DESC
        """
        return fetch_data_with_parameters(project, dataset, query, params, join_key)
    except Exception as e:
        print(f"Error fetching {table_name} data: {str(e)}")

# Function to fetch data using parameterized queries with dynamic project and dataset
def fetch_data_with_parameters(project, dataset, query, params, join_key):
    try:
        job_config = bigquery.QueryJobConfig(query_parameters=params)
        query_job = client.query(query, job_config=job_config, project=project, dataset=dataset)
        result_df = query_job.result().to_dataframe()
        # Add a prefix to columns to avoid conflicts when merging
        result_df.columns = [f"{join_key}_{col}" if col != 'company_number' else col for col in result_df.columns]
        return result_df
    except Exception as e:
        print(f"Error fetching data: {str(e)}")

# Example function to query main_table with parameters
def query_main_table(project, dataset):
    try:
        query = f"""
        SELECT entity_key, company_number, processingdate, other_fields
        FROM `{project}.{dataset}.main_table`
        """
        return fetch_data_with_parameters(project, dataset, query, [], 'main')
    except Exception as e:
        print(f"Error querying main table: {str(e)}")

# Main execution flow
if __name__ == "__main__":
    try:
        # Example dynamic project and dataset names
        main_project = 'your_main_project_id'
        main_dataset = 'your_main_dataset'
        holgroup_project = 'your_holgroup_project_id'
        holgroup_dataset = 'your_holgroup_dataset'
        scorecheck_project = 'your_scorecheck_project_id'
        scorecheck_dataset = 'your_scorecheck_dataset'
        acl_project = 'your_acl_project_id'
        acl_dataset = 'your_acl_dataset'
        protectscore_project = 'your_protectscore_project_id'
        protectscore_dataset = 'your_protectscore_dataset'

        # Query main table
        main_table = query_main_table(main_project, main_dataset)

        # Convert processingdate to timestamp
        main_table['processingdate'] = main_table['processingdate'].apply(convert_to_timestamp)

        # Fetch and merge holgroup data (holdingco)
        holgroup_data = fetch_data_from_table(holgroup_project, holgroup_dataset, 'holgroup', main_table,
                                              'main', ['holdingco'])
        if holgroup_data is not None:
            main_table = main_table.merge(holgroup_data, on='company_number', how='left')

        # Fetch holdingco-specific scorecheck data (uhc_score, uhc_grade)
        if 'holdingco' in main_table.columns:
            scorecheck_data = fetch_data_from_table(scorecheck_project, scorecheck_dataset, 'scorecheck', main_table,
                                                    'main', ['score AS uhc_score', 'grade AS uhc_grade'])
            if scorecheck_data is not None:
                main_table = main_table.merge(scorecheck_data, on='company_number', how='left')

        # Fetch and merge acl data (finallimit)
        acl_data = fetch_data_from_table(acl_project, acl_dataset, 'acl', main_table,
                                         'main', ['finallimit'])
        if acl_data is not None:
            main_table = main_table.merge(acl_data, on='company_number', how='left')

        # Fetch protectscore data (pscore)
        protectscore_data = fetch_data_from_table(protectscore_project, protectscore_dataset, 'protectscore', main_table,
                                                  'main', ['pscore'])
        if protectscore_data is not None:
            main_table = main_table.merge(protectscore_data, on='company_number', how='left')

        # Print or further process main_table with all merged data
        print(main_table.head())

    except Exception as e:
        print(f"Error in main execution flow: {str(e)}")
